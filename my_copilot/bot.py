import os
import asyncio
import logging
import tempfile
import json
import datetime
from dotenv import load_dotenv, find_dotenv
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI
from faster_whisper import WhisperModel
import edge_tts
import chromadb
from sentence_transformers import SentenceTransformer
from utils.skills import SkillManager, OPENCLAW_TOOLS
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
load_dotenv(find_dotenv())
TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DEEPSEEK_KEY = os.getenv("DEEPSEEK_API_KEY")

# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (STT, RAG, –ö–ª–∏–µ–Ω—Ç—ã)
print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
embed_model = SentenceTransformer('all-MiniLM-L6-v2')
client = OpenAI(api_key=DEEPSEEK_KEY, base_url="https://api.deepseek.com")

# 2.5 –•—Ä–∞–Ω–∏–ª–∏—â–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–¥–ª—è –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
USER_DATA_FILE = "user_data.json"
def save_user(chat_id):
    users = []
    if os.path.exists(USER_DATA_FILE):
        with open(USER_DATA_FILE, "r") as f: users = json.load(f)
    if chat_id not in users:
        users.append(chat_id)
        with open(USER_DATA_FILE, "w") as f: json.dump(users, f)

def get_users():
    if os.path.exists(USER_DATA_FILE):
        with open(USER_DATA_FILE, "r") as f: return json.load(f)
    return []

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤ (–≤ –ø–∞–º—è—Ç–∏)
user_histories = {}

# –°–µ—Ä–≤–µ—Ä –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (Heartbeat)
class HealthCheckHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        self.wfile.write(b"Alex Audi CoPilot is alive and running!")

    def log_message(self, format, *args):
        return # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –∫–æ–Ω—Å–æ–ª—å

def run_health_server():
    port = int(os.environ.get("PORT", 10000))
    logging.info(f"–ó–∞–ø—É—Å–∫ Heartbeat —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É {port}...")
    server = HTTPServer(('0.0.0.0', port), HealthCheckHandler)
    server.serve_forever()

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB
db_path = os.path.join(os.path.dirname(__file__), "chroma_db")
db_client = chromadb.PersistentClient(path=db_path)
try:
    collection = db_client.get_collection(name="audi_manual")
except:
    collection = None

# 3.5 –õ–∏—á–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –≤ ChromaDB
try:
    user_history_col = db_client.get_or_create_collection(name="user_history")
except:
    user_history_col = None

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¢–û
HISTORY_FILE = "service_history.json"
def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r") as f: return json.load(f)
    return {"oil_change": {"mileage": 145000, "date": "2024-01-01"}}

# 4. –§—É–Ω–∫—Ü–∏–∏
async def text_to_speech(text):
    communicate = edge_tts.Communicate(text, "ru-RU-SvetlanaNeural")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        tmp_path = tmp_file.name
        await communicate.save(tmp_path)
    return tmp_path

# 5. –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    save_user(update.effective_chat.id)
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –ê–ª–µ–∫—Å, —Ç–≤–æ–π –≤—Ç–æ—Ä–æ–π –ø–∏–ª–æ—Ç Audi A3. –Ø –ø–æ—É–º–Ω–µ–ª: —Ç–µ–ø–µ—Ä—å —Ç—ã –º–æ–∂–µ—à—å –ø—Ä–∏—Å–ª–∞—Ç—å –º–Ω–µ —Ñ–æ—Ç–æ —á–µ–∫–∞ –∏–∑ —Å–µ—Ä–≤–∏—Å–∞, –∏ —è –∑–∞–ø–æ–º–Ω—é –µ–≥–æ. –î–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –º–∞—à–∏–Ω–µ –Ω–∞–ø–∏—à–∏ /report.")

# 5.5 –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ (Jobs)
async def morning_job(context: ContextTypes.DEFAULT_TYPE):
    users = get_users()
    brief = SkillManager.get_proactive_briefing("–ö–∞–ª—É–≥–∞")
    for chat_id in users:
        try:
            await context.bot.send_message(chat_id=chat_id, text=brief, parse_mode="HTML")
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±—Ä–∏—Ñ {chat_id}: {e}")

async def report_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    report_text = SkillManager.generate_service_report()
    await update.message.reply_text(report_text, parse_mode="HTML")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo_file = await update.message.photo[-1].get_file()
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_img:
        await photo_file.download_to_drive(tmp_img.name)
        
        await update.message.reply_text("üëÅ –í–∏–∂—É –¥–æ–∫—É–º–µ–Ω—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Hugging Face –¥–ª—è '–∑—Ä–µ–Ω–∏—è' (–∫–∞–∫ –≤ Streamlit)
        hf_token = os.getenv("HUGGINGFACE_API_KEY")
        if not hf_token:
            await update.message.reply_text("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–ª—é—á HuggingFace –¥–ª—è –∑—Ä–µ–Ω–∏—è.")
            return

        from huggingface_hub import InferenceClient
        hf_client = InferenceClient(token=hf_token)
        
        try:
            with open(tmp_img.name, "rb") as f:
                img_bytes = f.read()
            
            # –ë–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–ª—è —á–µ–∫–æ–≤ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OCR, –Ω–æ –Ω–∞—á–Ω–µ–º —Å –æ–ø–∏—Å–∞–Ω–∏—è)
            description = hf_client.image_to_text(img_bytes, model="Salesforce/blip-image-captioning-large")
            text_desc = description[0]["generated_text"] if isinstance(description, list) else description
            
            # –ü–µ—Ä–µ–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ê–ª–µ–∫—Å—É, —á—Ç–æ–±—ã –æ–Ω –ø–æ–Ω—è–ª, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ
            system_prompt = "–¢—ã ‚Äî –ê–ª–µ–∫—Å. –¢–µ–±–µ –ø—Ä–∏—Å–ª–∞–ª–∏ —Ñ–æ—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –û–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ç–æ: " + text_desc + ". –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∑–∞–∫–∞–∑-–Ω–∞—Ä—è–¥ –∏–ª–∏ —á–µ–∫, –≤—ã–¥–µ–ª–∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (—á—Ç–æ —á–∏–Ω–∏–ª–∏, –∫–∞–∫–æ–π –ø—Ä–æ–±–µ–≥). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏, —á—Ç–æ –≤–∏–¥–∏—à—å."
            
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": "–ß—Ç–æ –Ω–∞ —ç—Ç–æ–º —Ñ–æ—Ç–æ?"}]
            )
            answer = response.choices[0].message.content
            await update.message.reply_text(f"üìù –ú–æ–π –∞–Ω–∞–ª–∏–∑:\n{answer}")
            
        except Exception as e:
            await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ñ–æ—Ç–æ: {e}")
        finally:
            os.remove(tmp_img.name)

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    hist = load_history()
    last = hist["oil_change"]
    await update.message.reply_text(f"üìä <b>–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å –¢–û:</b>\n–ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–º–µ–Ω–∞ –º–∞—Å–ª–∞: {last['date']} ({last['mileage']} –∫–º).", parse_mode="HTML")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if user_id not in user_histories:
        user_histories[user_id] = []

    # –ï—Å–ª–∏ –ø—Ä–∏—à–ª–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    text_prompt = None
    if update.message.voice:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as tmp_ogg:
            voice_file = await update.message.voice.get_file()
            await voice_file.download_to_drive(tmp_ogg.name)
            
            # STT
            with st.spinner("–°–ª—É—à–∞—é..."):
                segments, _ = whisper_model.transcribe(tmp_ogg.name, beam_size=5)
                text_prompt = " ".join([segment.text for segment in segments])
            if text_prompt:
                await update.message.reply_text(f"üé§ –ü–æ–Ω—è–ª: \"{text_prompt}\"")
    else:
        text_prompt = update.message.text

    # –û—Ç–≤–µ—Ç –æ—Ç –ê–ª–µ–∫—Å–∞
    if text_prompt:
        hist = load_history()
        last_oil = hist["oil_change"]
        
        # –ü–æ–∏—Å–∫ –≤ RAG (–î–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è + –õ–∏—á–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è)
        combined_context = ""
        query_vector = embed_model.encode(text_prompt).tolist()
        
        # 1. –ò–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        if collection:
            res_manual = collection.query(query_embeddings=[query_vector], n_results=2)
            combined_context += "\n–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ò–ù–°–¢–†–£–ö–¶–ò–ò:\n" + "\n".join(res_manual['documents'][0])
        
        # 2. –ò–∑ –∏—Å—Ç–æ—Ä–∏–∏ –º–∞—à–∏–Ω—ã
        if user_history_col:
            res_user = user_history_col.query(query_embeddings=[query_vector], n_results=3)
            if res_user['documents'][0]:
                combined_context += "\n–ò–ó –ò–°–¢–û–†–ò–ò –≠–¢–û–ô –ú–ê–®–ò–ù–´:\n" + "\n".join(res_user['documents'][0])

        service_info = f"–ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–º–µ–Ω–∞ –º–∞—Å–ª–∞: {last_oil['date']} –Ω–∞ {last_oil['mileage']} –∫–º."
        system_prompt = (
            f"–¢—ã ‚Äî –ê–ª–µ–∫—Å, –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤–æ–¥–∏—Ç–µ–ª—è Audi A3. {service_info}\n"
            "–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –ö –ò–°–¢–û–†–ò–ò –û–ë–°–õ–£–ñ–ò–í–ê–ù–ò–Ø —ç—Ç–æ–π –º–∞—à–∏–Ω—ã.\n"
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–æ—à–ª—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ –∏ —Ç–µ–∫—É—â–∏–º–∏ –∂–∞–ª–æ–±–∞–º–∏ (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞).\n"
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {combined_context}\n"
            "–í–ê–ñ–ù–û: –î–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û HTML-—Ç–µ–≥–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, <b>–∂–∏—Ä–Ω—ã–π</b>, <i>–∫—É—Ä—Å–∏–≤</i>). "
            "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π Markdown (–∑–≤–µ–∑–¥–æ—á–∫–∏). –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ —Å–ø–æ–∫–æ–π–Ω–æ."
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        user_histories[user_id].append({"role": "user", "content": text_prompt})
        # –î–µ—Ä–∂–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        user_histories[user_id] = user_histories[user_id][-10:]

        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "system", "content": system_prompt}] + user_histories[user_id],
                tools=OPENCLAW_TOOLS,
                tool_choice="auto"
            )
            
            msg = response.choices[0].message
            
            if msg.tool_calls:
                for tool_call in msg.tool_calls:
                    func_name = tool_call.function.name
                    args = json.loads(tool_call.function.arguments)
                    
                    logging.info(f"–ê–≥–µ–Ω—Ç –≤—ã–∑—ã–≤–∞–µ—Ç –Ω–∞–≤—ã–∫: {func_name}")
                    
                    if func_name == "get_weather":
                        result = SkillManager.get_weather(**args)
                    elif func_name == "get_part_info":
                        result = SkillManager.get_part_info(**args)
                    elif func_name == "log_car_event":
                        result = SkillManager.log_car_event(**args)
                        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å ChromaDB –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
                        if user_history_col:
                            now = datetime.datetime.now()
                            user_history_col.add(
                                ids=[str(now.timestamp())],
                                documents=[f"–°–æ–±—ã—Ç–∏–µ {now.strftime('%d.%m.%Y')}: {args['event_description']} (–ü—Ä–æ–±–µ–≥: {args.get('mileage', 0)} –∫–º)"],
                                embeddings=[embed_model.encode(args['event_description']).tolist()]
                            )
                    elif func_name == "remove_last_event":
                        result = SkillManager.remove_last_event()
                        # –í –∏–¥–µ–∞–ª–µ —Ç—É—Ç –Ω—É–∂–Ω–æ —É–¥–∞–ª–µ–Ω–∏–µ –∏–∑ ChromaDB, –Ω–æ –ø–æ–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è JSON
                        # —á—Ç–æ–±—ã –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å –ª–æ–≥–∏–∫—É ID.
                    else:
                        result = "–ù–∞–≤—ã–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω."
                    
                    user_histories[user_id].append(msg)
                    user_histories[user_id].append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": func_name,
                        "content": result
                    })
                    
                    final_res = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[{"role": "system", "content": system_prompt}] + user_histories[user_id]
                    )
                    answer = final_res.choices[0].message.content
            else:
                answer = msg.content
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
            user_histories[user_id].append({"role": "assistant", "content": answer})
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π HTML
            await update.message.reply_text(answer, parse_mode="HTML")
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ (TTS) –ü–†–ò–û–°–¢–ê–ù–û–í–õ–ï–ù–ê –ü–û –ü–†–û–°–¨–ë–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
            # try:
            #     audio_path = await text_to_speech(answer)
            #     if os.path.exists(audio_path):
            #         with open(audio_path, "rb") as audio:
            #             await update.message.reply_voice(audio)
            #         await asyncio.sleep(0.5)
            #         os.remove(audio_path)
            # except Exception as tts_err:
            #     logging.error(f"TTS Error: {tts_err}")
            
        except Exception as e:
            await update.message.reply_text(f"–£–ø—Å, –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∏: {e}")

# 6. –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    if not TG_TOKEN:
        print("–û—à–∏–±–∫–∞: TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
    else:
        app = Application.builder().token(TG_TOKEN).build()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ (Jobs)
        job_queue = app.job_queue
        # –£—Ç—Ä–µ–Ω–Ω–∏–π –±—Ä–∏—Ñ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 08:00 (–ø–æ UTC/—Å–µ—Ä–≤–µ—Ä–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏, –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å pytz)
        # –£—Ç—Ä–µ–Ω–Ω–∏–π –±—Ä–∏—Ñ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 08:00
        job_queue.run_daily(morning_job, time=datetime.time(hour=8, minute=0))
        
        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("status", status))
        app.add_handler(CommandHandler("report", report_command))
        app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
        app.add_handler(MessageHandler(filters.TEXT | filters.VOICE, handle_message))
        
        print("–ê–ª–µ–∫—Å –≤ –¢–µ–ª–µ–≥—Ä–∞–º–µ –∑–∞–ø—É—â–µ–Ω!")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º Heartbeat —Å–µ—Ä–≤–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        health_thread = threading.Thread(target=run_health_server, daemon=True)
        health_thread.start()
        
        app.run_polling()
