from dotenv import load_dotenv, find_dotenv
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–¥–µ–ª–∞–µ–º —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –≤—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –≤–∏–¥–µ–ª–∏ –∫–ª—é—á–∏)
load_dotenv(find_dotenv())

import streamlit as st
import os
import asyncio
import tempfile
import base64
import urllib.parse
from openai import OpenAI
from huggingface_hub import InferenceClient
from faster_whisper import WhisperModel
import edge_tts

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–≤–æ–π –∫–æ–º–∞–Ω–¥–æ–π Streamlit) ---
st.set_page_config(page_title="–ú–æ–π –í—Ç–æ—Ä–æ–π –ü–∏–ª–æ—Ç", page_icon="üöó", layout="centered", initial_sidebar_state="collapsed")

# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ò–ò
deepseek_key = os.getenv("DEEPSEEK_API_KEY")
hf_token = os.getenv("HF_TOKEN")

if not deepseek_key:
    st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω DEEPSEEK_API_KEY –≤ .env")
if not hf_token:
    st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω HF_TOKEN –≤ .env (–Ω—É–∂–µ–Ω –¥–ª—è –∫–∞–º–µ—Ä—ã)")

if deepseek_key:
    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")

if hf_token:
    client_vision = InferenceClient(token=hf_token)

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Whisper (STT) ---
@st.cache_resource
def load_whisper():
    # –£–¥–∞–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ 401 (Unauthorized)
    if "HF_TOKEN" in os.environ:
        del os.environ["HF_TOKEN"]
    if "HUGGINGFACE_HUB_TOKEN" in os.environ:
        del os.environ["HUGGINGFACE_HUB_TOKEN"]
    
    try:
        return WhisperModel("base", device="cpu", compute_type="int8")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}. –ü—Ä–æ–±—É—é –ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø...")
        return WhisperModel("base", device="cpu", compute_type="int8", local_files_only=False)

whisper_model = load_whisper()

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è (TTS) ---
async def text_to_speech(text):
    communicate = edge_tts.Communicate(text, "ru-RU-SvetlanaNeural")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        tmp_path = tmp_file.name
        await communicate.save(tmp_path)
    return tmp_path

# Custom CSS for mobile-like feel
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
        height: 60px;
        border-radius: 15px;
        font-size: 20px;
        font-weight: bold;
        margin-top: 10px;
        margin-bottom: 10px;
    }
    h1 { text-align: center; font-size: 2.5rem; margin-bottom: 20px; }
    .stChatInputContainer { padding-bottom: 20px; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

st.title("üöó –ú–æ–π –í—Ç–æ—Ä–æ–π –ü–∏–ª–æ—Ç")

# --- –ù–∞–≤–∏–≥–∞—Ü–∏—è ---
page = st.sidebar.radio("–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º", ["üß† –°–æ–≤–µ—Ç—á–∏–∫", "üëÅÔ∏è –ö–∞–º–µ—Ä–∞", "üßò –ú–∞—Ä—à—Ä—É—Ç"])

# --- –ë–õ–û–ö 1: –°–æ–≤–µ—Ç—á–∏–∫ (DeepSeek + Voice) ---
if page == "üß† –°–æ–≤–µ—Ç—á–∏–∫":
    st.header("–£–º–Ω—ã–π –°–æ–≤–µ—Ç—á–∏–∫")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞
    st.write("üé§ –ú–æ–∂–Ω–æ —Å–ø—Ä–æ—Å–∏—Ç—å –≥–æ–ª–æ—Å–æ–º:")
    audio_inp = st.audio_input("–ó–∞–ø–∏—Å–∞—Ç—å –≥–æ–ª–æ—Å", key="voice_input")

    voice_prompt = None
    if audio_inp:
        with st.spinner("–†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å..."):
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_audio:
                    tmp_audio.write(audio_inp.getvalue())
                    temp_audio_path = tmp_audio.name
                
                segments, _ = whisper_model.transcribe(temp_audio_path, beam_size=5)
                voice_prompt = " ".join([segment.text for segment in segments])
                st.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {voice_prompt}")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ STT: {e}")

    # –í—ã–≤–æ–¥ –∏—Å—Ç–æ—Ä–∏–∏
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant":
                if st.button("üîä –û–∑–≤—É—á–∏—Ç—å", key=f"audio_{i}"):
                    with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å..."):
                        audio_p = asyncio.run(text_to_speech(message["content"]))
                        st.audio(audio_p, format="audio/mp3")

    # –†–µ–∞–∫—Ü–∏—è –Ω–∞ –≤–≤–æ–¥ (—Ç–µ–∫—Å—Ç –∏–ª–∏ –≥–æ–ª–æ—Å)
    prompt = st.chat_input("–û–ø–∏—à–∏ —Å–∏—Ç—É–∞—Ü–∏—é:")
    if voice_prompt: # –ï—Å–ª–∏ –µ—Å—Ç—å –≥–æ–ª–æ—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        prompt = voice_prompt

    if prompt:
        if not deepseek_key:
            st.error("–î–æ–±–∞–≤—å—Ç–µ DEEPSEEK_API_KEY –≤ —Ñ–∞–π–ª .env")
        else:
            st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("assistant"):
                with st.spinner("–î—É–º–∞—é..."):
                    try:
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": "–¢—ã ‚Äî —Å–ø–æ–∫–æ–π–Ω—ã–π –∏ –æ–ø—ã—Ç–Ω—ã–π –∞–≤—Ç–æ–∏–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ø–æ –∏–º–µ–Ω–∏ –ê–ª–µ–∫—Å. –¢–≤–æ—è —Ü–µ–ª—å ‚Äî —Å–Ω–∏–∑–∏—Ç—å —Å—Ç—Ä–µ—Å—Å. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."},
                            ] + st.session_state.messages
                        )
                        answer = response.choices[0].message.content
                        st.markdown(answer)
                        st.session_state.messages.append({"role": "assistant", "content": answer})
                        
                        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–∑–≤—É—á–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –µ—Å–ª–∏ –±—ã–ª –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥
                        if voice_prompt:
                            audio_p = asyncio.run(text_to_speech(answer))
                            st.audio(audio_p, format="audio/mp3", autoplay=True)
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ DeepSeek: {e}")

# --- –ë–õ–û–ö 2: –ö–∞–º–µ—Ä–∞ (Hugging Face) ---
elif page == "üëÅÔ∏è –ö–∞–º–µ—Ä–∞":
    st.header("–ó–æ—Ä–∫–∏–π –ì–ª–∞–∑")
    st.warning("–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ HuggingFace (Qwen2-VL).")
    picture = st.camera_input("–°–¥–µ–ª–∞–π —Ñ–æ—Ç–æ –ø—Ä–∏–±–æ—Ä–Ω–æ–π –ø–∞–Ω–µ–ª–∏")
    
    if picture:
        st.image(picture, caption="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...", width=300)
        if not hf_token:
            st.error("–î–æ–±–∞–≤—å—Ç–µ HF_TOKEN –≤ —Ñ–∞–π–ª .env")
        else:
            with st.spinner("–°–º–æ—Ç—Ä—é..."):
                try:
                    image_bytes = picture.getvalue()
                    base64_image = base64.b64encode(image_bytes).decode('utf-8')
                    
                    completion = client_vision.chat.completions.create(
                        model="Qwen/Qwen2-VL-7B-Instruct",
                        messages=[{
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "–≠—Ç–æ —Ñ–æ—Ç–æ –ø—Ä–∏–±–æ—Ä–Ω–æ–π –ø–∞–Ω–µ–ª–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è. –ù–∞–∑–æ–≤–∏ –≥–æ—Ä—è—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã. –û–ø–∞—Å–Ω–æ –ª–∏ –µ—Ö–∞—Ç—å? –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫."},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                            ]
                        }],
                        max_tokens=500
                    )
                    answer = completion.choices[0].message.content
                    st.success(answer)
                    
                    # –û–∑–≤—É—á–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    if st.button("üîä –û–∑–≤—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç"):
                        audio_p = asyncio.run(text_to_speech(answer))
                        st.audio(audio_p, format="audio/mp3")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ç–æ-–º–æ–¥—É–ª—è: {e}")

# --- –ë–õ–û–ö 3: –ú–∞—Ä—à—Ä—É—Ç ---
elif page == "üßò –ú–∞—Ä—à—Ä—É—Ç":
    st.header("–°–ø–æ–∫–æ–π–Ω—ã–π –ø—É—Ç—å")
    start = st.text_input("–û—Ç–∫—É–¥–∞:", placeholder="–î–æ–º")
    end = st.text_input("–ö—É–¥–∞:", placeholder="–†–∞–±–æ—Ç–∞")
    
    if st.button("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç"):
        if not deepseek_key:
            st.error("–î–æ–±–∞–≤—å—Ç–µ DEEPSEEK_API_KEY –≤ —Ñ–∞–π–ª .env")
        elif start and end:
            with st.spinner("–ò—â—É –ø—É—Ç—å..."):
                try:
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": "–¢—ã —Å–ø–æ–∫–æ–π–Ω—ã–π –∞–≤—Ç–æ–∏–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä. –ü–æ–¥—Å–∫–∞–∂–∏ –Ω–æ–≤–∏—á–∫—É –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏ —Å–ø–æ–∫–æ–π–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç."},
                            {"role": "user", "content": f"–ò–∑ {start} –≤ {end}."}
                        ]
                    )
                    answer = response.choices[0].message.content
                    st.markdown(answer)
                    
                    # –û–∑–≤—É—á–∫–∞
                    audio_p = asyncio.run(text_to_speech(answer))
                    st.audio(audio_p, format="audio/mp3")

                    link = f"https://yandex.ru/maps/?rtext={urllib.parse.quote(start)}~{urllib.parse.quote(end)}&rtm=auto"
                    st.link_button("üó∫Ô∏è –û—Ç–∫—Ä—ã—Ç—å –≤ –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç–∞—Ö", link)
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞: {e}")
        else:
            st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–æ—á–∫–∏ –º–∞—Ä—à—Ä—É—Ç–∞")
